사이드 프로젝트 이름: AI 안테나
만들고 싶은 것: 자동화된 인공지능 뉴스레터, 인공지능이 만드는 인공지능 뉴스레터
설명: AI가 업계 뉴스를 크롤링하거나 수집하고, 일차적인 중요도를 판단하게 합니다. 중요한 뉴스에 대해서는 요약을 제공하고, 심화적인 내용은 RAG를 활용해 대답해줄 수 있게 합니다. 마지막으로 사람의 인사이트가 담긴 얘기는 직접 인터뷰하고 이를 정리, 기사를 작성해 함께 내보내는 것이 이 사이드 프로젝트의 목표입니다.

구현 방식 및 고려해야 할 것들:
1. 뉴스 크롤링
한글로 된 뉴스 기사는 몇 개를 크롤링할지
영어로 된 뉴스 기사는 몇 개를 크롤링할지
언론사에서 나온 기사가 아닌, 트위터나 sns에 올라온 글, 각종 빅테크 홈페이지의 보도자료는 어떻게 가져올지
크롤링 한 데이터는 어떤 형식으로 저장하고, 어떻게 관리할 것인지?
2. 중요한 뉴스 선별  - how?
어떤 뉴스가 중요한 뉴스인가 기준을 세우고 파이프라인화 하기
예를 들면, 뉴스에 기업 이름이 몇 번 이상 나왔다 / 제목에 어떤 기업 이름이 있다 / 뉴스에 특장 포맷을 가진 문장이 있다 ...
또는 챗GPT 활용할 수도 있음. 프롬프트를 정교하게 만들어서 API 사용해서 시키기. 
분류 모델을 사용해볼 수도 있다. 내가 직접 뉴스를 보고 o, x 태깅을 함. 그리고 bert같은 모델로 학습을 시키면 중요도를 확률로 계산시키고, 특정값 이상을 갖는 뉴스를 중요하게 판단할 수도 있어.
1차 필터링: 키워드 기반 (TF-IDF 활용)
2차 필터링: GPT-4나 Claude로 중요도 평가
3. 뉴스 요약 또는 설명 생성
OpenAI API나 Anthropic API 활용
구조화된 요약 템플릿 사용
4. 맞춤법이나 잘못된 내용이 없는지 팩트체크, 레퍼런스
맞춤법: PyKoSpacing, hanspell 라이브러리
팩트체크:
원문 링크 보관
GPT-4로 사실관계 재확인
인용문 정확성 검증
5. 사람이 검수 후 뉴스레터로 발송
최종 검토 및 발송
웹 기반 에디터 구축 (React + Node.js)
뉴스레터 플랫폼 연동 (Mailchimp API나 Substack API)

현재 진행 상황:
뉴스 크롤링 후 중복된 뉴스 제거하고 우선순위 매기는 단계까지 자동화 완료.
뉴스를 선택하는 부분에서 사람의 개입이 필요.
현재 뉴스레터를 블로그 및 Substack에 포스팅하는 중.
계속해서 고도화 예정.

중복 뉴스 제거하는 방법: tf-idf 사용
1. 제목과 요약문을 합친 새로운 칼럼을 만든다. 뉴스 1000개를 크롤링 한 csv 파일을 불러와서 일단 샘플로 나눈다. 
2. 새로 만든 칼럼의 각 행을 TF-IDF 벡터로 변환한다. = 이 행이 하나의 뉴스 기사이므로, 이 기사에 들어있는 단어가 그 기사에서 얼마나 중요한지에 따라 숫자가 매겨짐. 자주 등장하지만 다른 기사에도 많이 나오는 단어(예: "기자", "뉴스")는 낮은 점수 / 자주 등장하면서 다른 기사에는 별로 없는 단어(예: 특정 회사명)는 높은 점수
예: "삼성전자" + "스마트폰" -> "삼성전자 스마트폰"도 하나의 특성으로 포함
여기서 min_df = n 의 의미를 최소 "n개의 문서에서 등장하는 단어"를 포함시킨다는 뜻이다. 예를 들어서, 다음과 같은 뉴스들이 있다고 했을 때,
뉴스1: "삼성전자 신제품 스마트폰 공개"
뉴스2: "삼성전자 반도체 실적 발표"
뉴스3: "LG전자 로봇청소기 출시"
좀더 보기 좋게 해보면, sample_df['combined_text'][0]에 있던 모든 단어와 그 단어가 해당 문서에서 얼마나 중요한지 숫자로 나타나있다. 점수가 높은 단어는, 해당 문서에서 자주 등장하면서 다른 문서들에서는 덜 등장하는 단어들을 의미한다. 
3. 기사들의 코사인 유사도를 계산한다. = 모든 기사들 사이의 쌍을 지었을 때 얼마나 유사한지를 계산한다. 비슷한 단어를 비슷한 비중으로 포함하는 기사들은 높은 유사도를 갖게 된다.
4. tfidf 매트릭스를 가지고 모든 기사 쌍 사이의 코사인 유사도를 계산한다. 아까 그 문장을 가지고 코사인 유사도를 계산하면, 비슷한 단어를 비슷한 비중으로 포함하는 기사들은 높은 유사도를 갖는다. 
